---
title: 'Exploring text summarization'
date: 2020-09-25
permalink: /posts/2021/01/blog-post-2/
tags:
  - NLP
  - Abstractive Summarization
  - Neural Networks
---

The problem we investigated was exploring and improving text summarization. Between generated and extracted summaries, our main focus was to improve the quality of generated (abstractive) summary. In particular we focused on building upon PEGASUS, a SOTA transformer model and investigate ways to improve the qualitative performance of abstractive summaries. Proposed and implemented Self-Attention Guided Copy Mechanism which guides the summarization model to copy the important source words from the source doc/article to the summary. You can find the project at this [link](https://github.com/ericsengithub/AbstractiveSummarizationCSE291)

